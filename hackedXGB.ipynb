{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", sep=\";\")\n",
    "train = train.fillna(\"NR\")\n",
    "test = pd.read_csv(\"test.csv\", sep=\";\")\n",
    "test = test.fillna(\"NR\")\n",
    "target_name = \"prime_tot_ttc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change postal code to first two numbers if numeric\n",
    "def trunc_postal(x, letter_count):\n",
    "    if type(x) == int:\n",
    "        return int(str(x)[:letter_count])\n",
    "    elif type(x) == str and x != \"NR\":\n",
    "        return str(x)[:letter_count]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def transform_postal(df, letter_count):\n",
    "    df[\"codepostal_trunc_\" + str(letter_count)] = df[\"codepostal\"].apply(lambda x: trunc_postal(x, letter_count))\n",
    "    return df\n",
    "\n",
    "\n",
    "train = transform_postal(train, 3)\n",
    "test = transform_postal(test, 3)\n",
    "train = transform_postal(train, 2)\n",
    "test = transform_postal(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Т.е. если var12==3211, (как и при var12==0) можно считать, что этот параметр неизвестен.\n",
    "\n",
    "def fill_var12(x):\n",
    "    if x > 2000 or x < 0.1:\n",
    "        return \"NR\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "train[\"var12\"] = train[\"var12\"].apply(fill_var12)\n",
    "test[\"var12\"] = test[\"var12\"].apply(fill_var12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgbmape(y_pred, y_true): \n",
    "    labels = y_true.get_label()\n",
    "    return (\"mape\", -np.mean(np.abs((labels - y_pred) / labels)) * 100) #need - here due to weird overriding of maximize var in early stopping callback\n",
    "\n",
    "def mape(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_mapping(df, column_name):\n",
    "    \n",
    "    values = list(set(df[column_name].unique()))\n",
    "    grouped = df.groupby(column_name).mean()\n",
    "    average_targets = {}\n",
    "    \n",
    "    for category in grouped.index:\n",
    "        average_targets[category] = grouped.loc[category][target_name]\n",
    "    \n",
    "    return average_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = ['annee_naissance', 'annee_permis', 'marque', 'puis_fiscale', 'anc_veh', 'codepostal', 'energie_veh', 'kmage_annuel', 'crm', 'profession', 'var1', 'var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var8', 'var9', 'var10', 'var11', 'var12', 'var13', 'var14', 'var15', 'var16', 'var17', 'var18', 'var19', 'var20', 'var21', 'var22', \"codepostal_trunc_2\", \"codepostal_trunc_3\"]\n",
    "mappings = {col_name: categorical_mapping(train, col_name) for col_name in col_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform categorical values to mean target\n",
    "def transform_dataframe(df, mappings):\n",
    "    for col_name, mapping in mappings.items():\n",
    "        col_values = []\n",
    "        for i in df[col_name]:\n",
    "            if i in mapping.keys():\n",
    "                col_values.append(mapping[i])\n",
    "            elif \"NR\" in mapping.keys():\n",
    "                col_values.append(mapping[\"NR\"])\n",
    "            else:\n",
    "                col_values.append(statistics.mean(mapping.values()))\n",
    "        \n",
    "        df[col_name] = col_values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = transform_dataframe(train, mappings)\n",
    "test = transform_dataframe(test, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "test_ids = test[\"id\"]\n",
    "test = test[col_names]\n",
    "\n",
    "target = train[target_name]\n",
    "train = train[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_matrix = test.as_matrix()\n",
    "train_matrix = train.as_matrix()\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_by_size(train_matrix, eval_size):\n",
    "    train_size = len(train_matrix)\n",
    "    eval_set_size = int(eval_size * train_size)\n",
    "    eval_set_start = train_size - eval_set_size\n",
    "    eval_matrix = train_matrix[eval_set_start:]\n",
    "    new_train = train_matrix[:eval_set_start]\n",
    "    train_target = target[:eval_set_start]\n",
    "    eval_target = target[eval_set_start:]\n",
    "    \n",
    "    return new_train, eval_matrix, train_target, eval_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lr_callbacks import dynamic_lr, bold_driver, mc_clain, stc\n",
    "\n",
    "# decrease_function - takes current LR as input, returns a new one\n",
    "# rounds_function - takes number of LR decreases, returns allowed number of iterations that dont reduce eval score before applying decrease_function \n",
    "dynamic_lr = dynamic_lr(start_lr=0.5, min_lr=0.0001, decrease_function=lambda x: x*0.5, rounds_function=lambda x: int(5*x**1.6))\n",
    "bold_driver = bold_driver(start_lr=0.5, min_lr=0.005, boldness=1.005, timidness=0.5, relax=5, relax_k=2)\n",
    "mc_clain = mc_clain(start_lr=0.5, target_lr=0.001)\n",
    "stc = stc(start_lr=0.25, T=150)\n",
    "\n",
    "new_train, eval_matrix, train_target, eval_target = train_val_by_size(train_matrix, 0.1)\n",
    "eval_set = [(eval_matrix, eval_target)]\n",
    "xgmat = xgb.DMatrix(new_train, train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbms = []\n",
    "callbacks_to_test = [[], [stc], [bold_driver], [mc_clain]]\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.01,\n",
    "          \"max_depth\": 6}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# support class to redirect stderr\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "\n",
    "oldstdout = sys.stdout\n",
    "for i, cbs in enumerate(callbacks_to_test):\n",
    "    sys.stdout = open(\"xgb_\" + str(i) + \"_log.txt\", \"w\")\n",
    "    sys.stdout = flushfile(sys.stdout) \n",
    "    gbms.append(xgb.train(dtrain=xgmat, callbacks=cbs, params=params, num_boost_round=1000, early_stopping_rounds=15,\n",
    "                          verbose_eval=True, evals=[(xgb.DMatrix(eval_matrix, eval_target), \"val_0\")]))\n",
    "    \n",
    "sys.stdout = oldstdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def parse_xgb_log(fname):\n",
    "    iterations = []\n",
    "    accuracy = []\n",
    "    for line in open(fname):\n",
    "        if line.startswith(\"[\"):\n",
    "            iterations.append(int(line.split(\"[\")[1].split(\"]\")[0]))\n",
    "            accuracy.append(float(line.split(\":\")[1].strip()))\n",
    "    return iterations, accuracy\n",
    "\n",
    "colors = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\"]\n",
    "patches = []\n",
    "for i, cb in enumerate(callbacks_to_test):\n",
    "    if len(cb) < 3:\n",
    "        cb_name = \"default\"\n",
    "    else:\n",
    "        cb_name = str(cb[0]).split()[1].split(\".\")[0]\n",
    "    iterations, accuracy = parse_xgb_log(\"xgb_\" + str(i) + \"_log.txt\")\n",
    "    patches.append(mpatches.Patch(color=colors[i], label=cb_name))\n",
    "    sns.plt.plot(iterations, accuracy, colors[i])\n",
    "\n",
    "sns.plt.legend(handles=patches)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
